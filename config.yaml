global:
  # The topic used across prompts, this should be short and sweet
  topic: >
    Tool Use, the AI podcast
  # The overview of what your product/topic is, give as much detail as you'd like in here
  overview: >
    Tool Use is a weekly AI conversation where we talk about AI tools you can use in your life today. It's a podcast on youtube and other major podcast providers. The goal is to get more people to subscribe on youtube, and to get people listening on spotify.

  # General settings
  wait_time_between_runs: 86400 # 24 hours in seconds
  continue_conversation_for_n_messages: 1 # Set to more than 1 if you want the conversation to continue on artificially before submitting

# ========================================
# Model configuration
# ========================================
model_tiers:
  providers_to_use: ["gemini", "openai"] # The order matters. Remove a provider if you dont want to use it here.
  mini_models:
    enabled: true
    architect_agent: "openai/gpt-4o-mini"
    user_agent: "openai/gpt-4o-mini"
    system_agent: "openai/gpt-4o-mini"
    submission_model: "openai/gpt-4o"
    daily_token_limit: 100000
    # daily_token_limit: 10000000
    env_key: "TRAINING_OPENAI_API_KEY"
    submission_env_key: "TRAINING_OPENAI_API_KEY"

  full_models:
    enabled: true
    architect_agent: "openai/gpt-4o"
    user_agent: "openai/gpt-4o"
    system_agent: "openai/gpt-4o"
    submission_model: "openai/gpt-4o"
    daily_token_limit: 100000
    # daily_token_limit: 1000000
    env_key: "TRAINING_OPENAI_API_KEY"
    submission_env_key: "TRAINING_OPENAI_API_KEY"

  gemini_models:
    enabled: true
    architect_agent: "gemini/gemini-2.0-flash"
    user_agent: "gemini/gemini-2.0-flash"
    system_agent: "gemini/gemini-2.0-flash"
    submission_model: "gemini/gemini-2.0-flash"
    daily_request_limit: 20
    # daily_request_limit: 1500
    requests_per_minute: 15
    env_key: "GEMINI_API_KEY"
    submission_env_key: "TRAINING_OPENAI_API_KEY"

# ========================================
# Token Tracking configuration
# ========================================
token_tracking:
  tracking_file: "./logs/token_usage.json"
  stop_at_daily_token_limit: true
  auto_switch: true
  timezone: "UTC"
  min_tokens_percent: 1 # Stops when this percentage of the daily tokens remains

# ========================================
# Evals configuration
# ========================================
evaluation:
  enabled: true
  model: "openai/gpt-4o-mini"
  env_key: "TRAINING_OPENAI_API_KEY"
  cutoff_score: 85

# ========================================
# Vector DB configuration
# ========================================
vector_db:
  enabled: true
  index_name: "context_collection"
  chunk_size: 600
  chunk_overlap_percentage: 15
  similarity_threshold: 0.7
  embedding_model: "text-embedding-ada-002"
  persist_directory: "./chroma_db"

# ========================================
# Logging Configuration
# ========================================
logging:
  log_level: "DEBUG"
  log_file: "./logs/pipeline.log"
  rotation_size: "100 MB"
  retention_days: 1000
  compression: "zip"

  # ========================================
  # Paths for context and conversation artifacts, you shouldn't have to mess with this
  # ========================================
directories:
  context_folder: "./context/" # Folder containing markdown documentation & guidelines
  unprocessed_folder: "./conversations/unprocessed/"
  curated_folder: "./conversations/curated/"
  processed_folder: "./conversations/processed/"
